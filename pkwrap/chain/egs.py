# Copyright (c) 2020 Idiap Research Institute, http://www.idiap.ch/
#  Written by Srikanth Madikeri <srikanth.madikeri@idiap.ch>

import sys
import os
import random
from collections import OrderedDict, Counter
import logging
import argparse
from dataclasses import dataclass
from librosa.core.constantq import __num_two_factors
import torch
import torch.nn as nn
from torch.nn.utils import clip_grad_value_
import torch.optim as optim
from _pkwrap import kaldi
from . import chain
from . import matrix
from . import script_utils
from collections import defaultdict, namedtuple
import librosa
import subprocess
import io
from math import ceil

# take a scp file
class ChainExample(torch.utils.data.Dataset):
    """A Dataset wrapper to egs objects in Kaldi

    This is a generic wrapper to handling egs files generated by Kaldi.
    With this class we can iterate over the examples easily.
    """
    def __init__(self, egs_file, output_file=None):
        """Initialize a ChainExample object

        Given a egs_file, currently we support only scp files, we load
        the keys and pointers in the ark file into a dictionary, so that
        we don't have to load the entire egs file in memory

        Args:
            egs_file: scp file containing entries of egs
            output_file: this argument is used when each egs may belong to different languages
        """
        if output_file and egs_file.startswith('scp:'):
            raise ValueError("need egs_file to start to be of type scp when using output_file")
        self.egs_file = egs_file
#       TODO: error handling
        egs_list = [ln.strip().split() for ln in open(egs_file)]
        self.egs_dict = OrderedDict(egs_list)
        self.egs_keys = [x for x in self.egs_dict]
        if output_file:
            self.output_file = output_file
            self.lang_ids = dict([ln.strip().split() for ln in open(output_file)])
        else:
            self.output_file = None

    def __len__(self):
        return len(self.egs_dict)

    def __getitem__(self, idx):
        # key is the utterance id. it is likely to be a sub-utterance id
        key = self.egs_keys[idx]
        value = self.egs_dict[key]
        # if the output_file was passed, then language ids should exist
        if self.output_file:
            if key in self.lang_ids:
                lang_id = self.lang_ids[key]
            else:
                lang_id = -1
            return (key, value, lang_id)
        else:
            return (key, value, lang_id)


def load_egs(egs_file):
    """Loads the contents of the egs file.

    Given an egs file created for chain model training, load the
    contents of the and return as an array of NnetChainExample

    Args:
        egs_file: scp or ark file, should be prefix accordingly just like Kaldi

    Returns:
        A list of NnetChainExample
    """
    return kaldi.chain.ReadChainEgsFile(egs_file, 0)

def prepare_minibatch(egs_file, minibatch_size):
    """Prepare an array of minibatches from an egs file

    It loads the contents of the egs_file in memory, shuffles them
    and returns an array of minibatches.

    Args:
        egs_file: scp or ark file (a string), should be prefix accordingly just like Kaldi
        minibatch_size: a string of minibatch sizes separated by commas. E.g "64" or "128,64"

    Returns:
        A list of NnetChainExample. Each item contains merged examples with number of
        sequences as given in the minibatch_size
    """
    egs = load_egs(egs_file)
    random.shuffle(egs)
    merged_egs = kaldi.chain.MergeChainEgs(egs, str(minibatch_size))
    return merged_egs


@dataclass
class EgsInfo:
    name: str = ''
    wav: str = ''
    fst: str = ''
    duration: float = 0.
    num_output_frames: int = 0

def prepare_e2e_minibatch():
    pass

class BatchSampler(torch.utils.data.BatchSampler):
    def __iter__(self):
        batch_by_length = defaultdict(list)
        for idx in self.sampler:
            l = idx.duration
            batch_by_length[l].append(idx)
            if len(batch_by_length[l]) == self.batch_size:
                # we will have to normalize and merge egs
                yield prepare_e2e_minibatch(batch_by_length[l])
                batch_by_length[l] = []
        for l in batch_by_length:
            if batch_by_length[l] and not self.drop_last:
                yield prepare_e2e_minibatch(batch_by_length[l])

class E2EEgsDataset(torch.utils.data.Dataset):
    def __init__(self, egs_folder, cegs_idx, transition_model, normalization_fst, sampling_rate=16000):
        """instantiates a Pytorch Dataset for E2E training

        Args:
            egs_folder: the folder containing egs
            cegs_idx: index of egs, s.t. egs.1.scp exists
            transition_model: transition model that maps transition ids to pdf ids
            normalization_fst: fst to normalize when supervision is created
            sampling_rate: sampling rate of the audio files
        """
        self.transition_model = transition_model
        self.normalization_fst = normalization_fst
        self.sampling_rate = sampling_rate
        self.prepare_egs(egs_folder, cegs_idx)

    def __len__(self):
        return len(self.egs_holder)

    # TODO: test this function
    def process_egs(self, egs):
        min_diff = 100
        len_extend_context = 0
        # first read the wavfile
        try:
            p = subprocess.Popen(egs.wav, stdout=subprocess.PIPE)
            samples, sampling_rate = librosa.load(io.BytesIO(p.communicate()[0]), sr=self.sampling_rate)
            samples = samples.reshape(1, -1)
        except:
            raise IOError("Error processing {}".format(egs.name))
        duration = samples.shape[1]/sampling_rate
        if duration not in self.allowed_durations:
            raise ValueError("Cannot find duration for {}".format(egs.name))
        num_samples = samples.shape[1]
        num_output_frames = egs.num_output_frames
        fst = kaldi.fst.StdVectorFst()
        kaldi.fst.ReadKaldiFst(egs.fst, fst)
        supervision = kaldi.chain.Supervision()
        # TODO: make sure transition model is loaded
        if not kaldi.chain.TrainingGraphToSupervisionE2e(fst, self.trans_mdl, num_output_frames, supervision):
            raise Exception("Cannot convert fst to supervision for {}".format(egs.name))
        # TODO: add num_states function to Fst
        if self.normalization_fst is not None and self.normalization_fst.num_states() > 0:
            if not kaldi.chain.AddWeightToSupervisionFst(self.normalization_fst, supervision):
                logging.warning("FST was empty for utterance {}".format(egs.name))
        return supervision


    def __item__(self, i):
        # we may need to return wav and normalized fst instead
        return self.process_egs(self.egs_holder[i])

    # TODO: test this function
    def prepare_egs(self, egs_folder, cegs_index):
        # egs file is wav.scp file
        egs_file = "{}/cegs.{}.ark".format(egs_folder, cegs_index)
        fst_file = "{}/fst.{}.scp".format(egs_folder, cegs_index)
        utt2dur_file = "{}/utt2dur.{}".format(egs_folder, cegs_index)
        utt2len_file = "{}/utt2len.{}".format(egs_folder, cegs_index)
        utt2wav = self._read_wav_scp(egs_file)
        utt2dur = self._read_utt2dur_file(utt2dur_file)
        utt2len = self._read_utt2len_file(utt2len_file)
        egs_holder = self._get_egs_holder(fst_file, utt2wav, utt2dur, utt2len)

        allowed_durations_filename = "{}/allowed_durations.txt".format(egs_folder)
        self.allowed_durations = set([float(ln) for ln in open(allowed_durations_filename)])
        self.allowed_durations_sorted = sorted(list(self.allowed_durations))
        self.egs_holder = egs_holder

    def _read_wav_scp(self, wav_scp):
        utt2wav = {}
        with open(wav_scp) as ipf:
            for ln in ipf:
                lns = ln.strip().rstrip('|').split()
                uttname = lns[0]
                utt2wav[uttname] = lns[1:]
        return utt2wav

    # TODO: refactor this into some utilility that can read 2 column files
    def _read_utt2dur_file(self, utt2dur_file):
        """read utt2dur file"""
        utt2dur = {}
        with open(utt2dur_file) as utt2dur_f:
            for ln in utt2dur_f:
                lns = ln.strip().split()
                utt2dur[lns[0]] = float(lns[1])
        return utt2dur

    def _read_utt2len_file(self, utt2len_file):
        """read utt2len file, second column is the number of output frames"""
        utt2len = {}
        with open(utt2len_file) as utt2len_f:
            for ln in utt2len_f:
                lns = ln.strip().split()
                utt2len[lns[0]] = float(lns[1])
        return utt2len

    def _get_egs_holder(self, fst_file, utt2wav, utt2dur, utt2len):
        egs_holder = []
        with open(fst_file) as ipf:
            total, done, skipped = 0, 0, 0
            for ln in ipf:
                lns = ln.strip().split()
                total += 1
                try:
                    uttname, fstscp = lns
                except:
                    logging.error("Excepted fst file {} to have only 2 columns".format(fst_file))
                if uttname not in utt2wav:
                    skipped += 1
                    continue
                if uttname not in utt2dur:
                    logging.warning("Cannot find duration for {}".format(uttname))
                    skipped += 1
                    continue
                if uttname not in utt2len:
                    logging.warning("Cannot find number of output frames for {}".format(uttname))
                    skipped += 1
                    continue
                this_egs_info = EgsInfo(uttname, utt2wav[uttname], fstscp, utt2dur[uttname], utt2len[uttname])
                egs_holder.append(this_egs_info)
                done += 1
            logging.info("In get_egs_holder: total={}, done={}, skipped={}".format(total, done, skipped))
        return egs_holder
